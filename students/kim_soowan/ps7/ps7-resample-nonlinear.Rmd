---
title: "Problem set #7: resampling and nonlinearity"
author: "Soo Wan Kim"
date: "February 25, 2017"
output:
  github_document:
    toc: true
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)

library(tidyverse)
library(modelr)
library(broom)
library(pander)
library(knitr)
library(splines)
library(gam)

options(na.action = na.warn)
set.seed(1234) #set seed
theme_set(theme_bw()) #set theme for all plots

#import data
biden <- read.csv("data/biden.csv")
```

# Part 1: Sexy Joe Biden (redux) [4 points]

####Question  1 
**Estimate the training MSE of the model using the traditional approach. Fit the linear regression model using the entire dataset and calculate the mean squared error for the training set.**

```{r entire_set_MSE}
#function to calculate MSE
mse <- function(model, data) {
  x <- modelr:::residuals(model, data)
  mean(x ^ 2, na.rm = TRUE)
}

#estimate model
glm_trad <- glm(biden ~ age + female + educ + dem + rep, data = biden)
pander(tidy(glm_trad))

entire_mse <- mse(glm_trad, biden) #calculate MSE
```

The MSE for the model trained on the entire dataset is `r entire_mse`.

####Question 2
**Estimate the test MSE of the model using the validation set approach. How does this value compare to the training MSE from step 1?**

```{r validation_set_MSE}
biden_split <- resample_partition(biden, c(test = 0.3, train = 0.7)) #split data into 70/30 training/test set
biden_train <- biden_split$train %>% 
  tbl_df()
biden_test <- biden_split$test %>% 
  tbl_df()

biden_train_lm <- glm(biden ~ age + female + educ + dem + rep, data = biden_train) #estimate model on training set
pander(tidy(biden_train_lm))

validation_mse <- mse(biden_train_lm, biden_test) #calculate MSE using test set
```

The MSE calculated using the validation approach is `r validation_mse`. This is slightly higher than the MSE calculated using the traditional approach (`r entire_mse`). The model fitted using the validation approach only used 70% of the observations, so it is somewhat worse at predicting the results observed in the dataset than the model fitted on all the data.

####Question 3
**Repeat the validation set approach 100 times, using 100 different splits of the observations into a training set and a validation set. Comment on the results obtained.**
  
```{r validation_MSE_100}
mse_list <- vector(, 100) #set up empty vector of 100 items

#function to calculate the validation set MSE a certain number of times
validation_mse <- function(data, model, reps) {
  count <- 0
  while (count < reps) {
    split <- resample_partition(biden, c(test = 0.3, train = 0.7)) #split data into 70/30 training/test set
    train <- tbl_df(split$train) 
    test <- dplyr::tbl_df(split$test)
    train_lm <- glm(model, data = data) #estimate model
    validation_mse <- mse(train_lm, test) #calculate MSE
    mse_list[count + 1] <- validation_mse #append MSE values into vector
    count <- count + 1
  }
  return(mse_list)
}

#vector of results from repeating validation approach 100 times
mse_list <- validation_mse(biden, biden ~ age + female + educ + dem + rep, 100)

summary(mse_list)
mse_sd <- sd(mse_list)
```

The MSEs vary quite a bit, ranging from 338 to 450. The standard deviation of MSE estimates is `r mse_sd`. This shows that the results are highly dependent on which observations are picked for the training set. The average of these values is very close to the MSE obtained using the entire dataset.

####Question 4
**Estimate the test MSE of the model using the leave-one-out cross-validation (LOOCV) approach. Comment on the results obtained.**

```{r LOOCV_MSE, cache=TRUE}
loocv_data <- crossv_kfold(biden, k = nrow(biden)) #divide data into k folds where k = number of observations
loocv_models <- map(loocv_data$train, ~ glm(biden ~ age + female + educ + dem + rep, data = .)) #estimate model
loocv_mse_map <- map2_dbl(loocv_models, loocv_data$test, mse) #calculate MSEs
loocv_mse <- mean(loocv_mse_map, na.rm = TRUE) #get mean of MSEs
```

The MSE calculated using the LOOCV approach is `r loocv_mse`. This is similar to the MSE obtained using the entire dataset and the validation approach, and particularly to the mean of the MSEs obtained by repeating the validation approach 100 times. 

####Question 5
**Estimate the test MSE of the model using the 10-fold cross-validation approach. Comment on the results obtained.**

```{r 10-fold_CV_MSE}
biden_cv10 <- crossv_kfold(biden, k = 10) %>% #divide data set into 10 folds
  mutate(model = map(train, ~ lm(biden ~ age + female + educ + dem + rep, data = .)), #estimate model
         mse = map2_dbl(model, test, mse)) #calculate MSEs
cv10_mse <- mean(biden_cv10$mse, na.rm = TRUE) #get mean MSE
```

The MSE calculated using the 10-fold cross-validation approach is `r cv10_mse`. Again, this is similar to the other MSE estimates. It is especially very close to the LOOCV MSE and the mean of the MSEs from repeating the validation set approach 100 times.

####Question 6
**Repeat the 10-fold cross-validation approach 100 times, using 100 different splits of the observations into $10$-folds. Comment on the results obtained.**
  
```{r 10-fold_CV_MSE_100, cache=TRUE}
cv10_mse_list <- vector(, 100) #create vector of length 100

#function
cv10_mse <- function(data, model, reps) {
  count <- 0
  while (count < reps) {
    folded <- crossv_kfold(data, k = 10) #divide data set into 10 folds
    folded$mod <- map(folded$train, ~glm(model, data = .)) #estimate model
    folded$mse <- map2_dbl(folded$mod, folded$test, mse) #calculate MSEs
    cv10_mse <- mean(folded$mse, na.rm = TRUE) #get mean of MSEs
    cv10_mse_list[count + 1] <- cv10_mse #store in vector
    count <- count + 1
  }
  return(cv10_mse_list)
}

cv10_mse_list <- cv10_mse(biden, biden ~ age + female + educ + dem + rep, 100)
summary(cv10_mse_list)
mse_sd <- sd(cv10_mse_list)
```

This time, the estimates vary very little, with a standard deviation of only `r mse_sd`. This shows that the 10-fold cross validation method produces estimates much more reliable and unbiased than those of the validation set approach. However, the mean of the estimates using this method is almost identical to the mean of the MSEs from repeating the validation set approach 100 times. 

####Question 7
**Compare the estimated parameters and standard errors from the original model in step 1 (the model estimated using all of the available data) to parameters and standard errors estimated using the bootstrap ($n = 1000$).**

**Original model estimates**

```{r original_est}
pander(tidy(glm_trad))
```

**Bootstrap estimates**

```{r bootstrap, cache=TRUE}
#estimate model using bootstrap, display in tidy format
boot <- biden %>%
  modelr::bootstrap(1000) %>%
  mutate(model = map(strap, ~ glm(biden ~ age + female + educ + dem + rep, data = .)), 
         coef = map(model, tidy))

boot_est <- boot %>%
  unnest(coef) %>%
  group_by(term) %>%
  summarize(est.boot = mean(estimate),
            se.boot = sd(estimate, na.rm = TRUE))
boot_est
```

The estimates for parameters and standard errors are very nearly the same across the two approaches.

# Part 2: College (bivariate) [3 points]

```{r college_import}
college <- read.csv("data/College.csv")
```

####Private or public

Since `Private` is a categorical variable with only two values, I fit a linear model with no transformation, as follows:

```{r private_lm}
private_mod <- glm(Outstate ~ Private, data = college)
pander(tidy(private_mod))
```

The estimated effect of a university being private is large and highly statistically significant. A private university is expected to have an out-of-state tuition rate around $5000 higher than that of a public university.

```{r private_plots}
private_mod_pred <- college %>%
  add_predictions(private_mod) %>%
  add_residuals(private_mod)

ggplot(private_mod_pred, aes(resid)) +
  geom_freqpoly(aes(color = Private)) + 
  labs(title ="Distribution of residuals for private/public-only model", 
       subtitle = "Outstate ~ Private")
```

The residuals peak around 0 for both private and public universities, but residuals are somewhat more negative for private universities and there appear to be some clustering in different areas, suggesting that other factors have important effects.

####Room and board costs

```{r roomboard_exp_plot}
ggplot(college, aes(Room.Board, Outstate)) +
  geom_point() +
  geom_smooth() + 
  labs(title = "Room and board costs vs. Out-of-state tuition",
       subtitle = "Fitted with smoothing line",
       x = "Room and board costs ($)",
       y = "Out-of-state tuition ($)")
```

The relationship appears fairly linear, but it looks like the relationship could be quadratic or cubic for some ranges of the x value. I fit a more flexible model using splines below.

```{r roomboard_splines}
# function to simplify things
RB_spline_cv <- function(data, degree = 3, df = NULL){
  # estimate the model on each fold
  models <- map(data$train, ~ glm(Outstate ~ bs(Room.Board, df = df, degree = degree),
                                  data = .))
  # calculate mse for each test fold
  models_mse <- map2_dbl(models, data$test, mse)
  
  return(mean(models_mse, na.rm = TRUE))
}

# fold the data
college_kfold <- crossv_kfold(college, k = 10)

# estimate mse for polynomial degrees in 1:10
RB_degree_mse <- data_frame(degrees = 1:10,
                                    mse = map_dbl(degrees, ~ RB_spline_cv(college_kfold, degree = ., df = 3 + .))) %>%
  arrange(mse)

# estimate mse for degrees of freedom (aka knots)
RB_df_mse <- data_frame(df = 1:10,
                                mse = map_dbl(df, ~ RB_spline_cv(college_kfold, df = 3 + .))) %>%
  arrange(mse)

ggplot(RB_degree_mse, aes(degrees, mse)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = 1:10) +
  labs(title = "Optimal number of degrees for out-of-state tuition spline regression",
       subtitle = "Knots = 3",
       x = "Highest-order polynomial",
       y = "10-fold CV MSE")

ggplot(RB_df_mse, aes(df, mse)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = 1:10) +
  labs(title = "Optimal number of knots for out-of-state tuition spline regression",
       subtitle = "Highest-order polynomial = 3",
       x = "Knots",
       y = "10-fold CV MSE")
```

The estimates and resulting graphs are different every time I calculate the MSEs, but the number of degrees does not appear to make a significant difference in terms of MSE as long as the number is less than 7 (MSE does not reach a noticeable global minimum). The optimal number of knots is between 5 and 7. 

Using 2 degrees and 6 knots, the regression estimates are as follows:

```{r roomboard_splines_optim_model}
RB_optim <- glm(Outstate ~ bs(Room.Board, df = 6, degree = 2), data = college)
summary(RB_optim)
```

The relationship is highly statistically significant for all knots other than the first, possibly due to lack of data for lower values of `Room.Board`. The p-value is also relatively big for the last knot, suggesting the observations were more sparse at the higher end of the predictor value. Given more data, the overall relationship could be linear, but it could also be that the effect of `Room.Board` is different at extreme values. On the whole, it looks like higher room and board costs are associated with higher tuition rates.

```{r roomboard_splines_optim_plot}
augment(RB_optim, newdata = data_grid(college, Room.Board)) %>%
  mutate(.fitted_low = .fitted - 1.96 * .se.fit,
         .fitted_high = .fitted + 1.96 * .se.fit) %>%
  ggplot(aes(Room.Board, .fitted)) +
  geom_point(data = college, aes(y = Outstate), alpha = .1) +
  geom_line() +
  geom_line(aes(y = .fitted_low), linetype = 2) +
  geom_line(aes(y = .fitted_high), linetype = 2) +
  geom_vline(xintercept = attr(bs(college$Room.Board, df = 6, degree = 2), "knots"),
             linetype = 2, color = "blue") +
  labs(title = "Second-order polynomial spline of out-of-state tuition",
       subtitle = "Knots = 6",
       x= "Room and board costs ($)",
       y = "Predicted out-of-state tuition ($)")
```

####Percent of faculty with Ph.D.'s

```{r phd_exp_plot}
ggplot(college, aes(PhD, Outstate)) +
  geom_point() +
  geom_smooth() + 
  labs(title = "Percent of faculty with PhDs vs. Out-of-state tuition",
       subtitle = "Fitted with smoothing line",
       x = "Percent of faculty with PhDs",
       y = "Out-of-state tuition ($)")
```

Based on the plot, it looks like the relationship between `PhD` and `Outstate` could be cubic. I first fit a model with monotonic transformation (log of `Outstate` regressed on `PhD`), then a spline regression.

```{r phd_monotonic}
college <- college %>%
  mutate(logoutstate = log(Outstate)) #take log of Outstate

ggplot(college, aes(x = PhD, y = logoutstate)) + 
  geom_point() +
  geom_smooth() + 
  labs(title = "Percent of faculty with PhDs vs. Log out-of-state tuition",
       subtitle = "Fitted with smoothing line",
       x = "Percent of faculty with PhDs",
       y = "Log of out-of-state tuition in dollars")
```

The smoothing line is flatter, but still follows a curve rather than a straight line. It does not look like there are different patterns for different ranges of `PhDsq`, and the curve is fairly smooth. To confirm, I calculate the optimal conditions for a spline regression below.

```{r phd_splines}
# function to simplify things
phd_spline_cv <- function(data, degree = 3, df = NULL){
  # estimate the model on each fold
  models <- map(data$train, ~ glm(Outstate ~ bs(PhD, df = df, degree = degree),
                                  data = .))
  # calculate mse for each test fold
  models_mse <- map2_dbl(models, data$test, mse)
  
  return(mean(models_mse, na.rm = TRUE))
}

# fold the data
college_kfold <- crossv_kfold(college, k = 10)

# estimate mse for polynomial degrees in 1:10
phd_degree_mse <- data_frame(degrees = 1:10,
                                    mse = map_dbl(degrees, ~ phd_spline_cv(college_kfold, degree = ., df = 3 + .))) %>%
  arrange(mse)

# estimate mse for degrees of freedom (aka knots)
phd_df_mse <- data_frame(df = 1:10,
                                mse = map_dbl(df, ~ phd_spline_cv(college_kfold, df = 3 + .))) %>%
  arrange(mse)

ggplot(phd_degree_mse, aes(degrees, mse)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = 1:10) +
  labs(title = "Optimal number of degrees for out-of-state tuition spline regression",
       subtitle = "Knots = 3",
       x = "Highest-order polynomial",
       y = "10-fold CV MSE")

ggplot(phd_df_mse, aes(df, mse)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = 1:10) +
  labs(title = "Optimal number of knots for out-of-state tuition spline regression",
       subtitle = "Highest-order polynomial = 3",
       x = "Knots",
       y = "10-fold CV MSE")
```

Again, the estimates are not stable, but on the whole it seems that increasing the number of degrees or knots from 1 does not significantly improve model fit. Thus, I apply another transformation (squaring `PhD`) to allow for a linear regression.

```{r phd_monotonic2}
college <- college %>%
  mutate(PhDsq = PhD^2) #take square of PhD

phd_optim <- glm(logoutstate ~ PhDsq, data = college)
summary(phd_optim)
```

The relationship is statistically significant, but the parameter estimate is close to zero. The estimate suggests that a one-point increase in the square of the percentage of faculty with PhDs increases the out-of-state tuition by less than 1%.

```{r phd_optim_plot}
ggplot(college, aes(x = PhDsq, y = logoutstate)) + 
  geom_point() +
  geom_smooth(method = "lm") + 
  labs(title = "Percent of faculty with PhDs (squared) vs. Log out-of-state tuition",
       subtitle = "Fitted with OLS line",
       x = "Square of percent of faculty with PhDs",
       y = "Log of out-of-state tuition in dollars")
```

####Percent of alumni who donate

```{r perc_exp_plot}
ggplot(college, aes(perc.alumni, Outstate)) +
  geom_point() +
  geom_smooth() + 
  labs(title = "Percent of alumni who donate vs. Out-of-state tuition",
       subtitle = "Fitted with smoothing line",
       x = "Percent of alumni who donate",
       y = "Out-of-state tuition ($)")
```

The relation appears strikingly linear. Indeed, the optimal number of degrees and knots (df) for a spline regression are both 1, as shown below:

```{r perc_spline}
# function to simplify things
perc_spline_cv <- function(data, degree = 3, df = NULL){
  # estimate the model on each fold
  models <- map(data$train, ~ glm(Outstate ~ bs(perc.alumni, df = df, degree = degree),
                                  data = .))
  # calculate mse for each test fold
  models_mse <- map2_dbl(models, data$test, mse)
  
  return(mean(models_mse, na.rm = TRUE))
}

# fold the data
college_kfold <- crossv_kfold(college, k = 10)

# estimate mse for polynomial degrees in 1:10
perc_degree_mse <- data_frame(degrees = 1:10,
                                    mse = map_dbl(degrees, ~ perc_spline_cv(college_kfold, degree = ., df = 3 + .))) %>%
  arrange(mse)

# estimate mse for degrees of freedom (aka knots)
perc_df_mse <- data_frame(df = 1:10,
                                mse = map_dbl(df, ~ perc_spline_cv(college_kfold, df = 3 + .))) %>%
  arrange(mse)

ggplot(perc_degree_mse, aes(degrees, mse)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = 1:10) +
  labs(title = "Optimal number of degrees for out-of-state tuition spline regression",
       subtitle = "Knots = 3",
       x = "Highest-order polynomial",
       y = "10-fold CV MSE")

ggplot(perc_df_mse, aes(df, mse)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = 1:10) +
  labs(title = "Optimal number of knots for out-of-state tuition spline regression",
       subtitle = "Highest-order polynomial = 3",
       x = "Knots",
       y = "10-fold CV MSE")
```

Thus, I estimate a linear model with no transformation.

```{r perc_optim_mod}
perc_optim <- glm(Outstate ~ perc.alumni, data = college)
summary(perc_optim)
```

The relationship is highly statistically significant and the effect appears to be substantial. A one-percent increase in the percent of alumni who donate is associated with an increase of about $180 in out-of-state tuition. This seems counterintuitive, as more donations would increase funds for subsidizing tuition. 

####Instructional expenditure per student

```{r}
ggplot(college, aes(Expend, Outstate)) +
  geom_point() +
  geom_smooth() + 
  labs(title = "Expenditure per student vs. Out-of-state tuition",
       subtitle = "Fitted with smoothing line",
       x = "Instructional expenditure per student ($)",
       y = "Out-of-state tuition ($)")
```

The relationship looks like it follows a cube root or log pattern overall, but there appears to be some discontinuity at the lower end. 

```{r exp_spline}
# function to simplify things
exp_spline_cv <- function(data, degree = 3, df = NULL){
  # estimate the model on each fold
  models <- map(data$train, ~ glm(Outstate ~ bs(Expend, df = df, degree = degree),
                                  data = .))
  # calculate mse for each test fold
  models_mse <- map2_dbl(models, data$test, mse)
  
  return(mean(models_mse, na.rm = TRUE))
}

# fold the data
college_kfold <- crossv_kfold(college, k = 10)

# estimate mse for polynomial degrees in 1:10
exp_degree_mse <- data_frame(degrees = 1:10,
                                    mse = map_dbl(degrees, ~ exp_spline_cv(college_kfold, degree = ., df = 3 + .))) %>%
  arrange(mse)

# estimate mse for degrees of freedom (aka knots)
exp_df_mse <- data_frame(df = 1:10, mse = map_dbl(df, ~ exp_spline_cv(college_kfold, df = 3 + .))) %>%
  arrange(mse)

ggplot(exp_degree_mse, aes(degrees, mse)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = 1:10) +
  labs(title = "Optimal number of degrees for out-of-state tuition spline regression",
       subtitle = "Knots = 3",
       x = "Highest-order polynomial",
       y = "10-fold CV MSE")

ggplot(exp_df_mse, aes(df, mse)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = 1:10) +
  labs(title = "Optimal number of knots for out-of-state tuition spline regression",
       subtitle = "Highest-order polynomial = 3",
       x = "Knots",
       y = "10-fold CV MSE")
```

Again, the number of degrees is unimportant. The optimal number of knots appears to be 2 or 3. Using 3 degrees and 2 knots, the regression estimates are as follows:

```{r exp_splines_optim_model}
exp_optim <- glm(Outstate ~ bs(Expend, df = 2, degree = 3), data = college)
summary(exp_optim)
```

The relationship is highly statistically significant and substantial at all knots. This suggests an increase in expenditure per student substantially raises tuition costs on average, which makes sense given that tuition rates help cover the costs of instruction.

```{r exp_splines_optim_plot}
augment(exp_optim, newdata = data_grid(college, Expend)) %>%
  mutate(.fitted_low = .fitted - 1.96 * .se.fit,
         .fitted_high = .fitted + 1.96 * .se.fit) %>%
  ggplot(aes(Expend, .fitted)) +
  geom_point(data = college, aes(y = Outstate), alpha = .1) +
  geom_line() +
  geom_line(aes(y = .fitted_low), linetype = 2) +
  geom_line(aes(y = .fitted_high), linetype = 2) +
  geom_vline(xintercept = attr(bs(college$Expend, df = 2, degree = 3), "knots"),
             linetype = 2, color = "blue") +
  labs(title = "Third-order polynomial spline of out-of-state tuition",
       subtitle = "Knots = 2",
       x= "Expenditure per student ($)",
       y = "Predicted out-of-state tuition ($)")
```

####Graduation rate

```{r grad_exp_plot}
#clean data
college$Grad.Rate[college$Grad.Rate > 100] <- NA
 
ggplot(filter(college, !is.na(Grad.Rate)), aes(Grad.Rate, Outstate)) +
  geom_point() +
  geom_smooth() + 
  labs(title = "Graduation rate vs. Out-of-state tuition",
       subtitle = "Fitted with smoothing line",
       x = "Graduation rate",
       y = "Out-of-state tuition ($)")
```

The smoothing line follows an interesting, almost S-shaped curve. It looks like the relationship could be linear with better data. In fact, the optimal number of degrees and knots (df) for a spline regression are both 1.

```{r grad_spline}
# function to simplify things
grad_spline_cv <- function(data, degree = 3, df = NULL){
  # estimate the model on each fold
  models <- map(data$train, ~ glm(Outstate ~ bs(Grad.Rate, df = df, degree = degree),
                                  data = .))
  # calculate mse for each test fold
  models_mse <- map2_dbl(models, data$test, mse)
  
  return(mean(models_mse, na.rm = TRUE))
}

# fold the data
college_kfold <- crossv_kfold(college, k = 10)

# estimate mse for polynomial degrees in 1:10
grad_degree_mse <- data_frame(degrees = 1:10,
                                    mse = map_dbl(degrees, ~ grad_spline_cv(college_kfold, degree = ., df = 3 + .))) %>%
  arrange(mse)

# estimate mse for degrees of freedom (aka knots)
grad_df_mse <- data_frame(df = 1:10, mse = map_dbl(df, ~ grad_spline_cv(college_kfold, df = 3 + .))) %>%
  arrange(mse)

ggplot(grad_degree_mse, aes(degrees, mse)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = 1:10) +
  labs(title = "Optimal number of degrees for out-of-state tuition spline regression",
       subtitle = "Knots = 3",
       x = "Highest-order polynomial",
       y = "10-fold CV MSE")

ggplot(grad_df_mse, aes(df, mse)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = 1:10) +
  labs(title = "Optimal number of knots for out-of-state tuition spline regression",
       subtitle = "Highest-order polynomial = 3",
       x = "Knots",
       y = "10-fold CV MSE")
```

Thus, I fit a linear model with no transformation, as follows:

```{r grad_optim_mod}
grad_optim <- glm(Outstate ~ Grad.Rate, data = college)
summary(grad_optim)
```

The effect is both substantial and highly significant. A one-percent increase in the graduation rate is expected to raise out-of-state tuition by around $135. This is probably because the tuition rate is calculated based on the value of the education, which includes the probability of graduating with a degree.

```{r grad_optim_plot}
#clean data
college$Grad.Rate[college$Grad.Rate > 100] <- NA
 
ggplot(filter(college, !is.na(Grad.Rate)), aes(Grad.Rate, Outstate)) +
  geom_point() +
  geom_smooth(method = "lm") + 
  labs(title = "Graduation rate vs. Out-of-state tuition",
       subtitle = "Fitted with OLS regression line",
       x = "Graduation rate",
       y = "Out-of-state tuition ($)")
```

# Part 3: College (GAM) [3 points]

####Questions 1 & 2

**Split the data into a training set and a test set.**

```{r college_split}
college_split <- resample_partition(college, c(test = 0.3, train = 0.7)) #split data into 70/30 training/test set
college_train <- college_split$train %>% 
  tbl_df()
college_test <- college_split$test %>% 
  tbl_df()
```

**Estimate an OLS model on the training data, using out-of-state tuition (Outstate) as the response variable and the other six variables as the predictors. Interpret the results and explain your findings, using appropriate techniques (tables, graphs, statistical tests, etc.).**

```{r college_train_OLS}
college_train_lm <- glm(Outstate ~ Private + Room.Board + PhD + perc.alumni + Expend + Grad.Rate, 
                       data = college_train) #estimate model on training set
summary(college_train_lm)
```

All of the predictors have a statistically significant relationship with out-of-state tuition. Room and board costs and expenditure per student have very small effects, however. The biggest impact comes from whether the university is private. Out-of-state tuition is expected to be higher by more than $2000 dollars if the university is private rather than public. The percent of alumni who donate, the percent of faculty with PhDs, and the graduation rate have much smaller but still tangible effects, all in the positive direction. 

As the variance-covariance matrix below shows, the relationships are probably not independent. For example, The percent of faculty with PhDs has a high positive correlation with whether the university is private, possibly because private universities are more likely to have the financial resources to attract more highly trained faculty. The percent of alumni who donate is highly negatively correlated with whether the university is private, again possibly because private universities tend to be wealthier. Interestingly, graduation rate is negatively correlated with the university being private as well. The effect of the university being private or public likely biases the separate effects of these factors with the model used. To better account for the independent effects of other factors, the model should incorporate interaction effects between predictors.

```{r college_OLS_cov}
vcov(college_train_lm)
```

###Question 3

**Estimate a GAM on the training data, using out-of-state tuition (Outstate) as the response variable and the other six variables as the predictors. You can select any non-linear method (or linear) presented in the readings or in-class to fit each variable. Plot the results, and explain your findings. Interpret the results and explain your findings, using appropriate techniques (tables, graphs, statistical tests, etc.).**

Below I fit a GAM using the specifications from part 2.

```{r college_gam}
college_gam <- gam(Outstate ~ Private + PhDsq + perc.alumni + Grad.Rate + 
                     bs(Room.Board, df = 6, degree = 2) + 
                     bs(Expend, df = 2, degree = 3), 
                   data = college_train, na.action = na.fail)
summary(college_gam)
```

####Private or Public

```{r gam_private}
# get graphs of each term
college_gam_terms <- preplot(college_gam, se = TRUE, rug = FALSE)

## private
data_frame(x = college_gam_terms$Private$x,
           y = college_gam_terms$Private$y,
           se.fit = college_gam_terms$Private$se.y) %>%
  unique %>%
  mutate(y_low = y - 1.96 * se.fit,
         y_high = y + 1.96 * se.fit,
         x = factor(x)) %>%
  ggplot(aes(x, y, ymin = y_low, ymax = y_high)) +
  geom_errorbar() +
  geom_point() +
  scale_x_discrete(labels = c("Public", "Private")) + 
  labs(title = "GAM of out-of-state tuition",
       x = NULL,
       y = expression(f[1](Private)))
```

The effect of university type is statistically and substantively significant. A private university likely to have a much higher tuition rate than a public university.

####Percent of faculty with Ph.D.'s (squared)

```{r}
data_frame(x = college_gam_terms$PhDsq$x,
           y = college_gam_terms$PhDsq$y,
           se.fit = college_gam_terms$PhDsq$se.y) %>%
  mutate(y_low = y - 1.96 * se.fit,
         y_high = y + 1.96 * se.fit) %>%
  ggplot(aes(x, y)) +
  geom_line() +
  geom_line(aes(y = y_low), linetype = 2) +
  geom_line(aes(y = y_high), linetype = 2) +
  labs(title = "GAM of out-of-state tuition",
       x = "Square of percent of faculty with PhDs",
       y = expression(f[2](PhDsq)))
```

The 95% confidence intervals get extremely wide as x-values approach the minimum or maximum, and practically always include 0 for every value of `PhDsq`. This suggests the relationship with out-of-state tuition is not significant. 

####Percent of alumni who donate

```{r}
data_frame(x = college_gam_terms$perc.alumni$x,
           y = college_gam_terms$perc.alumni$y,
           se.fit = college_gam_terms$perc.alumni$se.y) %>%
  mutate(y_low = y - 1.96 * se.fit,
         y_high = y + 1.96 * se.fit) %>%
  ggplot(aes(x, y)) +
  geom_line() +
  geom_line(aes(y = y_low), linetype = 2) +
  geom_line(aes(y = y_high), linetype = 2) +
  labs(title = "GAM of out-of-state tuition",
       x = "Percent of alumni who donate",
       y = expression(f[3](perc.alumni)))
```

The 95% confidence intervals get wide toward the ends, but the effect appears to be substantial judging by the slope of the line.

####Graduation rate

```{r}
data_frame(x = college_gam_terms$Grad.Rate$x,
           y = college_gam_terms$Grad.Rate$y,
           se.fit = college_gam_terms$Grad.Rate$se.y) %>%
  mutate(y_low = y - 1.96 * se.fit,
         y_high = y + 1.96 * se.fit) %>%
  ggplot(aes(x, y)) +
  geom_line() +
  geom_line(aes(y = y_low), linetype = 2) +
  geom_line(aes(y = y_high), linetype = 2) +
  labs(title = "GAM of out-of-state tuition",
       x = "Graduation Rate",
       y = expression(f[4](Grad.Rate)))
```

Again, the confidence intervals are sizable, but the slope of the line suggests graduation rate still has a significant effect.

####Room and board costs

```{r}
data_frame(x = college_gam_terms$`bs(Room.Board, df = 6, degree = 2)`$x,
           y = college_gam_terms$`bs(Room.Board, df = 6, degree = 2)`$y,
           se.fit = college_gam_terms$`bs(Room.Board, df = 6, degree = 2)`$se.y) %>%
  mutate(y_low = y - 1.96 * se.fit,
         y_high = y + 1.96 * se.fit) %>%
  ggplot(aes(x, y)) +
  geom_line() +
  geom_line(aes(y = y_low), linetype = 2) +
  geom_line(aes(y = y_high), linetype = 2) +
  labs(title = "GAM of out-of-state tuition",
       subtitle = "Second-order polynomial spline, 6 knots",
       x = "Room and board costs ($)",
       y = expression(f[5](Room.Board)))
```

The 95% confidence intervals get very wide toward the ends of the x-axis but are fairly narrow in the middle range. There does appear to be a significant, if not large effect of room and board costs on out-of-state tuition.

####Instructional expenditure per student

```{r}
data_frame(x = college_gam_terms$`bs(Expend, df = 2, degree = 3)`$x,
           y = college_gam_terms$`bs(Expend, df = 2, degree = 3)`$y,
           se.fit = college_gam_terms$`bs(Expend, df = 2, degree = 3)`$se.y) %>%
  mutate(y_low = y - 1.96 * se.fit,
         y_high = y + 1.96 * se.fit) %>%
  ggplot(aes(x, y)) +
  geom_line() +
  geom_line(aes(y = y_low), linetype = 2) +
  geom_line(aes(y = y_high), linetype = 2) +
  labs(title = "GAM of out-of-state tuition",
       subtitle = "Third-order polynomial spline, 2 knots",
       x = "Instructional expenditure per student ($)",
       y = expression(f[6](Expend)))
```

The confidence intervals get progressively wider as `Expend` increases, probably because of sparse observations. On the other hand, the curve shows a clear and dramatic upward trend before it starts to slope downward at the higher values of `Expend`. This suggests that expenditure per student does have a significant effect on out-of-state tuition, at least when expenditure is not very high.

###Question 4

**Use the test set to evaluate the model fit of the estimated OLS and GAM models, and explain the results obtained.**

```{r GAM_OLS_model_fit}
OLS_validation_mse <- mse(college_train_lm, college_test)
GAM_validation_mse <- mse(college_gam, college_test)

college_pred <- college_test %>%
  add_residuals(college_train_lm) %>%
  rename(resid_OLS = resid) %>%
  add_residuals(college_gam) 

# distribution of residuals
ggplot(college_pred) +
  geom_freqpoly(aes(resid), color = "red") + 
  geom_freqpoly(aes(resid_OLS), color = "blue") + 
  labs(title ="Distribution of residuals for OLS and GAM models", 
       caption = "Blue = OLS, Red = GAM")
```

The MSE for the OLS model is `r OLS_validation_mse`, and the MSE for the GAM model is `r GAM_validation_mse`. The GAM MSE is lower, suggesting that the GAM model is a better fit. The distribution of residuals suggests that it is also less biased. The residuals from the GAM model peak at zero, whereas the OLS residuals peak to the left of zero.

###Question 5

**For which variables, if any, is there evidence of a non-linear relationship with the response?**

To test for non-linearity, I conducted ANOVA tests on all of the non-binary predictor variables. There is evidence of a non-linear relationship with `Outstate` for only `PhD` and `Expend`, which makes sense given the graphs plotted previously.

####PhD
```{r college_phd_anova}
#PhD
gam.m1=gam(Outstate~ Private + Room.Board + PhD + perc.alumni + Expend + Grad.Rate, 
           data=college_train, na.action = na.fail)
gam.m2=gam(Outstate~ Private + Room.Board + bs(PhD, degree = 2) + perc.alumni + Expend + Grad.Rate,  
           data=college_train, na.action = na.fail)
anova(gam.m1, gam.m2, test="F")
```

####Expend
```{r college_expend_anova}
#Expend
gam.m1=gam(Outstate~ Private + Room.Board + PhD + perc.alumni + Expend + Grad.Rate, 
           data=college_train, na.action = na.fail)
gam.m2=gam(Outstate~ Private + Room.Board + PhD + perc.alumni + bs(Expend, degree = 2) + Grad.Rate,  
           data=college_train, na.action = na.fail)
anova(gam.m1, gam.m2, test="F")
```

```{r session_info, include=FALSE}
devtools::session_info()
```
