---
title: "PS7"
author: "Chelsea Ernhofer"
output: github_document
---

```{r include = FALSE}
require(mosaic)
require(gap)

library(tidyverse)
library(modelr)
library(broom)
library(gam)
library(splines)
library(MASS)
options(digits=3)


biden_data = read.csv("biden.csv")
options(na.action = na.warn)
attach(biden_data)
```

##Question 1
```{r}
biden_lm = lm(biden ~ age + female + educ + dem + rep, data = biden_data)
summary(biden_lm)

tidy(biden_lm)

```
Above is a summary of the linear regression, including the coefficient values and the standard errors for each on the included variables. 

##Part 1
```{r}
mse <- function(model, data) {
  x <- modelr:::residuals(model, data)
  mean(x ^ 2, na.rm = TRUE)
}

biden_mse = mse(biden_lm, biden_data)

biden_mse
```

##Part 2
```{r}
set.seed(1234)
biden_split = resample_partition(biden_data, c(test = 0.3, train = 0.7))

train_lm = lm(biden ~ age + female + educ + dem + rep, data = biden_split$train)

test_mse = mse(train_lm, biden_split$test)

test_mse
```
The two values I MSE calculated from the testing and training data are quite similar. The MSE created using the training linear model and testing data (400) was higher than the previous MSE (398), but this is not completely out of the ordinary since we are using two different subsets of the data. It is likely that in the first calculation, we overfit the model very slightly which led to the increased MSE when using a new set of data. However, since the two MSEs are very similar, I believe that this model is not incredibly overfit. 

##Part 3
```{r}
mse100 = numeric(100)

for (i in 1:100){
  split = resample_partition(biden_data, c(test = 0.3, train = 0.7))
  train_lm = lm(biden ~ age + female + educ + dem + rep, data = split$train)
  test_mse = mse(train_lm, split$test)
  
  mse100[i] = test_mse
  
  }


mse_mean = mean(mse100)

histogram(mse100, type = "density", breaks = 10, col = "lightblue", main= "Distribution of 100 MSE values: Training and Testing Data")

mse_mean #399
```
After running this resampling procedure, I can conclude that a testing MSE of 400 is normal. The mean of my 100 sampled MSEs is 399 which is only slightly higher than the MSE calculated with all of the data (397).

##Part 4
```{r}
  loocv_data <- crossv_kfold(biden_data, k = nrow(biden_data))
  loocv_models <- map(loocv_data$train, ~ lm(biden ~ age + female + educ + dem + rep, data = .))
  loocv_mse <- map2_dbl(loocv_models, loocv_data$test, mse)
  mean(loocv_mse)
```
These results are the closest to the original MSE calculated so far. The MSE calculated with all of the data was 397 and the results from the leave one out cross-validation was 398. However, the one downside to this method is the speed of it. Since it is doing n number of calculations, the loocv is significantly slower than any other method. 

##Part 5

```{r}
  loocv_data <- crossv_kfold(biden_data, k = 10)
  loocv_models <- map(loocv_data$train, ~ lm(biden ~ age + female + educ + dem + rep, data = .))
  loocv_mse <- map2_dbl(loocv_models, loocv_data$test, mse)
  mean(loocv_mse)

```
This method produced the same results as the loocv method and was much quicker. 

##Part 6
```{r}
kmse100 = numeric(100)

for (i in 1:100){
  loocv_data <- crossv_kfold(biden_data, k = 10)
  loocv_models <- map(loocv_data$train, ~ lm(biden ~ age + female + educ + dem + rep, data = .))
  loocv_mse <- map2_dbl(loocv_models, loocv_data$test, mse)
  test_mse = mean(loocv_mse)
  
  kmse100[i] = test_mse
  
}

mean(kmse100)
histogram(kmse100, type = "density", breaks = 10, col = "lightblue", main= "Distribution of 100 MSE values: Cross Validation k=10")

```
After running the k-fold resampling simulation 100 times, I can conclude that a MSE of 398 is normal. 

##Part 7

```{r}
biden_boot <- biden_data %>%
  modelr::bootstrap(1000) %>%
  mutate(model = map(strap, ~ lm(biden ~ age + female + educ + dem + rep, data = .)),
         coef = map(model, tidy))

biden_boot %>%
  unnest(coef) %>%
  group_by(term) %>%
  summarize(est.boot = mean(estimate),
            se.boot = sd(estimate, na.rm = TRUE))

```

```{r}
tidy(biden_lm)

```
Between the original linear model and the one created through the bootstrap, the coefficients do not vary greatly. As expected, the standard errors for almost all coefficients are larger in the bootstrap than in the original linear model (with the exception of education and gender). This makes sense since the bootstrap method does not rely on any assumptions of the distribution and therefore has larger errors, on average. 

##Question 2

##Model 1: Terminal and Outstate

For my first predictor variable, I chose Terminal which measures the percent of faculty with terminal degrees. To start, I plotted the two variables against each other to see if I could visually detect whether the relationship was linear or non-linear. 
```{r}
college_data = read.csv("College.csv")
glimpse(college_data)
attach(college_data)
ggplot(college_data, aes(Terminal, Outstate)) +
  geom_point() +
  geom_smooth(method = "loess") +
  labs(title = "Terminal professors and Out of State Tuition")
```
From this plot, I began to suspect that this relationship was, perhaps, non-linear. To investigate further, I plotted the residuals against the predicted values to see if there were patterns. If the relationship was truly linear, there would be not systematic patterns in the distribution of the residuals, the plotted line would be straight and horizontal at a value of 0 for residuals.


```{r}

sim_linear_mod <- glm(Outstate ~ Terminal, data = college_data)

sim_linear_pred <- college_data %>%
  add_predictions(sim_linear_mod) %>%
  add_residuals(sim_linear_mod)

ggplot(sim_linear_pred, aes(pred, resid)) +
  geom_point() +
  geom_smooth(se = FALSE) +
  labs(title = "Plot of residuals of solely linear model: Terminal vs Outstate",
       x = "Predicted values",
       y = "Residuals")
```
This plot gives more evidence to support the claim that the relationship between Terminal and Outstate is not linear. There is a clear visual correlation between the residuals and the predicted values. From this plot, I am confident that I should relax the linear assumption between the two variables in order to create a better model.

Once I decided to relax the linear assumption for this variable, I first plotted the linear regression line to be able to compare it against the other models I created. 
```{r}

ggplot(sim_linear_mod, aes(Terminal)) +
  geom_point(data = college_data, aes(Terminal, Outstate)) +
  geom_line(aes(y = .fitted), col="blue") +
  labs(title = "Outstate Tuition costs and Terminal Professors",
       x = "Terminal",
       y = "Out of State Tuition")

```

I then performed a general linear regression using the squared values for my explanatory variable, calculated the mean squared errors for the relaxed linear model to compare to the pure linear model, and plotted this regression line. 
```{r}
term_out = glm(Outstate ~ I(Terminal^2), data = college_data)

summary(term_out) 

mse(sim_linear_mod, college_data)

mse(term_out, college_data)

```
Above we see that a one unit increase in about of professors with terminal degrees results in a $sqrt(7.94)_$ increase in out of state tuition. The MSE for this regresssion is smaller than for the purely linear regression, which indicates that this model better fits our data. 

```{r}

# plot the curve
ggplot(term_out, aes(Terminal)) +
  geom_point(data = college_data, aes(Terminal, Outstate)) +
  geom_line(aes(y = .fitted), col="blue") +
  labs(title = "Outstate Tuition costs and Terminal Professors",
       x = "Terminal squared",
       y = "Out of State Tuition")

```
Visually, there is not a dramatic difference between this regression line and the linear regression line. However, the line does appear linealy relaxed and looks like a good fits for the general pattern of the data. 

Next, I ran a polynomial regression to see if I could find a better fitting model. 

```{r}

term_out_glm = glm(Outstate ~ I(Terminal^2) + I(Terminal^3) + I(Terminal^4), data = college_data)

summary(term_out_glm)

mse(term_out_glm, college_data)

mse(sim_linear_mod, college_data)


```
This MSE is even smaller than the first relaxed-linear model. However, when looking at the summary of the model, it appears as though the relationship between outstate and the polynomial versions of terminal are not significant. 


```{r}

ggplot(term_out_glm, aes(Terminal)) +
  geom_point(data = college_data, aes(Terminal, Outstate)) +
  geom_line(aes(y = .fitted), col="blue") +
  labs(title = "Outstate Tuition costs and Terminal Professors",
       x = "Terminal Polynomial",
       y = "Out of State Tuition")

```
The plot of this regression line is also less linear. It appears to fit the data very well. 


##Model 2: Graduate Rate and Outstate

```{r}
#expend
#PhD
#Grad.Rate
#Terminal

ggplot(college_data, aes(Grad.Rate, Outstate)) +
  geom_point() +
  geom_smooth(method = "loess") +
  labs(title = "Out of State Tuition and Graduation Rate")


```
```{r}
lm_grad <- glm(Outstate ~ Grad.Rate, data = college_data)

sim_linear_pred <- college_data %>%
  add_predictions(lm_grad) %>%
  add_residuals(lm_grad)

ggplot(sim_linear_pred, aes(pred, resid)) +
  geom_point() +
  geom_smooth(se = FALSE) +
  labs(title = "Plot of residuals of solely linear model: Graduation Rate and Outstate",
       x = "Predicted values",
       y = "Residuals")

```
This plot shows that the residuals are fairly randomly patterned. Looking at this plot, it is less clear whether a relaxed linear model is necessary to explore the relationship between graduation rate  and outstate tuition. In order to further explore the potential need for non-linearity in this model, I made a histogram to look at the distribution of the residuals. 

```{r}
grad_pred <- college_data %>%
  add_predictions(lm_grad) %>%
  add_residuals(lm_grad)

# distribution of residuals
ggplot(grad_pred, aes(resid)) +
  geom_histogram(aes(y = ..density..)) +
  stat_function(fun = dnorm,
                args = list(mean = mean(grad_pred$resid),
                            sd = sd(grad_pred$resid))) +
  labs(title = "Linear model for a linear relationship",
       x = "Residuals")

```
The distribution of the residuals, while not perfectly normal, is very close to the normal distribution. There is no clear way in which these data stray from the normal distribution. Because of this, I am content to model this relationship in a purely linear way. 

```{r}
grad_glm = glm(Outstate ~Grad.Rate, data = college_data)

summary(grad_glm)

mse(grad_glm, college_data)

```
From this model, we can expect that for every unit increase in graduation rate, there is a 133 unit increase in out of state tuition. This result is statistically significant. 

```{r}

ggplot(grad_glm, aes(Grad.Rate)) +
  geom_point(data = college_data, aes(Grad.Rate, Outstate)) +
  geom_line(aes(y = .fitted), col="blue") +
  labs(title = "Outstate Tuition costs and Graduation Rate",
       x = "Graduation Rate",
       y = "Out of State Tuition")

```

##Model 3: S.F. Ratio

```{r}
ggplot(college_data, aes(S.F.Ratio, Outstate)) +
  geom_point() +
  geom_smooth(method = "auto") +
  labs(title="Relationship between S.F.Ratio and Outstate")
```
Looking at this scatter plot, it appears as though there is a negative relationship between S.F. Ration and Outstate tuition. The relationship may need to have relaxed linearity because of a few outliers in the data. 

```{r}
sim_linear <- college_data
sim_linear_mod <- glm(Outstate ~ S.F.Ratio, data = sim_linear)

sim_linear_pred <- sim_linear %>%
  add_predictions(sim_linear_mod) %>%
  add_residuals(sim_linear_mod)

ggplot(sim_linear_pred, aes(pred, resid)) +
  geom_point() +
  geom_smooth(se = FALSE) +
  labs(title = "Predicted vs. Residuals for the S.F.Ratio predictor",
       x = "Predicted values",
       y = "Residuals")
```
Looking at the plot, it appears as though there are patterns in the residuals which would indicate a need for non-linearity in this relationship. I have chosen to do splines. 

```{r}
sim_piece <- college_data

sim_piece_smooth <- glm(Outstate ~ bs(S.F.Ratio, knots = c(5)), data = sim_piece)

sim_piece %>%
  add_predictions(sim_piece_smooth) %>%
  ggplot(aes(S.F.Ratio)) +
  geom_point(aes(y = Outstate)) +
  geom_line(aes(y = pred), size = 1) +
  geom_vline(xintercept = 10, linetype = 2, color = "blue") +
  labs(title = "Cubic spline",
       x = "X",
       y = "Y") +
  theme(legend.position = "none")
```
Using 5 knots allows for more flexibility in the model which can be seen in the above plot. 


```{r}
data_frame(terms = c(1, 5, 10),
           models = map(terms, ~ glm(Outstate ~ bs(S.F.Ratio, df = . + 3), data = sim_piece)),
           pred = map(models, ~ add_predictions(sim_piece, .))) %>%
  unnest(pred) %>%
  ggplot(aes(S.F.Ratio, Outstate)) +
  geom_point(data = sim_piece, alpha = .2) +
  geom_line(aes(y = pred, color = factor(terms))) +
  labs(title = "Cubic spline",
       x = "X",
       y = "Y",
       color = "Knots")
```
Again, it seems as though the model with 5 knots is the best fit because it is flexible, but is hopefully not overfitting the model. The line with 10 knots appears to move more with the data, but this will most likely lead to overfitting when using the testing data.


##Question 3

##Part 1 
```{r}

college_split = resample_partition(college_data, c(test = 0.3, train = 0.7))

split_glm = glm(Outstate ~ Private + Room.Board + PhD + perc.alumni + Expend + Grad.Rate, data = college_split$train)

summary(split_glm)

```
From this model, we can see the different relationships between out of state tuition and other variables. All relationships are statistically significant. If a university is private it is asociated with a ~18.40 unit increase in out of state tuition. This makes sense since private universities are often more expensive for both instate and out of state students. A one unit increase in room and board is associate with a 9.92 unit increase in out of state tuition. A one unit increase in percent of faculty with PhDs results in a 3.76 increase in out of state tuition. A one unit increase in percentage of alumni who donate to the university results in a 4.2 increase in out of state tuition. This relationship is interesting to me since one would think that more alumni support would mean that current students may be charged less for tuition. A one unit increase in expenditures per student results in a 2.44 increase in out of state tuition and a unit increase in graduation rate is associated with a 2.77 increase in out of state tuition. 

```{r}
train_df = data.frame(college_split$train)

train_df %>%
  add_predictions(split_glm) %>%
  add_residuals(split_glm) %>%
  {.} -> grid2
gridpriv <- filter(grid2, Private == "Yes")
gridnopriv <- filter(grid2, Private == "No")
ggplot(grid2, aes(jitter(pred, 8))) +
  geom_point(aes(y = jitter(resid, 8))) +
  geom_smooth(method='lm', aes(y = resid, color = 'Private'), data = gridpriv, size = 1) +
  geom_smooth(method='lm', aes(y = resid, color = 'Not Private'), data = gridnopriv, size = 1) +
  labs(title = "Out of State Tuition: Predicted Values and Residuals",
        x = "Outstate Tuition",
        y = "Residuals")

```
From this plot we can see that for private schools, the residuals of the multivariate regression are normally distributed. The residuals for non-private schools seem less normal. This could indicate a non-linear relationship between not private schools and out of state tuition. 

##Part 3
```{r}

outstate_gam <- gam(Outstate ~ lo(PhD) + lo(perc.alumni) + log(Expend) + lo(Grad.Rate) + Private + log(Room.Board), data = college_split$train, na.action = na.fail)

summary(outstate_gam)

```
The results of the GAM are above, including coefficients and siginificance levels. It is interesting to note that relationships between Outstate and all predictor variables are siginificant. It appears as though as relationships are also positive. 


```{r}
grid_gam <- train_df %>%
  add_predictions(outstate_gam)%>%
  add_residuals(outstate_gam)

ggplot(grid_gam, aes(x = pred, y = resid)) +
  geom_point() +
  geom_smooth()+
  labs(title = 'Predicted value against residual of GAM',x = 'pred',y = 'resid')


```
The residual plot above shows a random-looking distribution of the residuals. This indicates that we have done a good job modelling out of state tuition since there don't appear to be any systematic patterns in the residuals of this model. 

To further test the accuracy of this model, I've made plots of the GAMs of the inidividual variables. 
```{r}
gam_terms <- preplot(outstate_gam, se = TRUE, rug = FALSE)

data_frame(x = gam_terms$`lo(perc.alumni)`$x,
           y = gam_terms$`lo(perc.alumni)`$y,
           se.fit =  gam_terms$`lo(perc.alumni)`$se.y) %>%
  mutate(y_low = y - 1.96 * se.fit,
         y_high = y + 1.96 * se.fit) %>%
  ggplot(aes(x, y)) +
  geom_line() +
  geom_line(aes(y = y_low), linetype = 2) +
  geom_line(aes(y = y_high), linetype = 2) +
  labs(title = "Percent Alumni and Outstate, GAM",
       x = "Percent Alumni",
       y = expression(f[1](perc.alumni)))

```
Percent Alumni was assumed to have a linear relationship with outstate tuition and it appears as though this relationship holds. The 95% confidence interval is wider when a school has more that 40% alumni who contribute to the school, but this could be because less schools have more than 40% alumni contributing. 

```{r}
data_frame(x = gam_terms$`log(Expend)`$x,
           y = gam_terms$`log(Expend)`$y,
           se.fit = gam_terms$`log(Expend)`$se.y) %>%
  mutate(y_low = y - 1.96 * se.fit,
         y_high = y + 1.96 * se.fit) %>%
  ggplot(aes(x, y)) +
  geom_line() +
  geom_line(aes(y = y_low), linetype = 2) +
  geom_line(aes(y = y_high), linetype = 2) +
  labs(title = "Logged Expenditures per student and Outstate Tuition, GAM",
       x = "Expend",
       y = expression(f[3](expend)))

```
Logged expenditures seem to fit into this model well. 

```{r}
data_frame(x = gam_terms$`log(Room.Board)`$x,
           y = gam_terms$`log(Room.Board)`$y,
           se.fit = gam_terms$`log(Room.Board)`$se.y) %>%
  mutate(y_low = y - 1.96 * se.fit,
         y_high = y + 1.96 * se.fit) %>%
  ggplot(aes(x, y)) +
  geom_line() +
  geom_line(aes(y = y_low), linetype = 2) +
  geom_line(aes(y = y_high), linetype = 2) +
  labs(title = "Logged Room/Board costs and Outstate Tuition, GAM",
       x = "Room and Board",
       y = expression(f[3](Room.Board)))

```
Room and Board appears to have a positive relationship with outstate tuition. The slope does not decrease or increase dramatically with increased Room and Board, so one would assume that there is a steady increase between these two variables. 
```{r}

data_frame(x = gam_terms$`lo(Grad.Rate)`$x,
           y = gam_terms$`lo(Grad.Rate)`$y,
           se.fit =  gam_terms$`lo(Grad.Rate)`$se.y) %>%
  mutate(y_low = y - 1.96 * se.fit,
         y_high = y + 1.96 * se.fit) %>%
  ggplot(aes(x, y)) +
  geom_line() +
  geom_line(aes(y = y_low), linetype = 2) +
  geom_line(aes(y = y_high), linetype = 2) +
  labs(title = "Graduation Rate and Outstate, GAM",
       x = "Graduation Rate",
       y = expression(f[1](Grad.Rate)))

```

```{r}
data_frame(x = gam_terms$`lo(PhD)`$x,
           y = gam_terms$`lo(PhD)`$y,
           se.fit =  gam_terms$`lo(PhD)`$se.y) %>%
  mutate(y_low = y - 1.96 * se.fit,
         y_high = y + 1.96 * se.fit) %>%
  ggplot(aes(x, y)) +
  geom_line() +
  geom_line(aes(y = y_low), linetype = 2) +
  geom_line(aes(y = y_high), linetype = 2) +
  labs(title = "PhD and Outstate, GAM",
       x = "PhD",
       y = expression(f[1](PhD)))

```

##Part 4

In order to evaluate the fit of this model (both the OLS version and GAM version), I will calculate the MSE for both models. 

```{r}
ols <- mse(split_glm, college_split$test)
gam <- mse(outstate_gam, college_split$test)
ols
gam


```
From this test, we can see that the GAM model best fits the data. 


##Part 5

```{r}
gam1 = gam(Outstate ~ lo(PhD) + lo(perc.alumni) + log(Expend) + lo(Grad.Rate) + Private + log(Room.Board), data = college_split$train, na.action = na.fail)

gam2 = gam(Outstate ~ lo(PhD) + lo(perc.alumni) + Private + lo(Expend) + log(Room.Board), data = college_split$train, na.action = na.fail)

gam3 = gam(Outstate ~ lo(PhD) + lo(perc.alumni) + Private + log(Expend) + lo(Room.Board), data = college_split$train, na.action = na.fail)

gam4 = gam(Outstate ~ lo(PhD) + lo(perc.alumni) + Private + lo(Expend) + lo(Room.Board), data = college_split$train, na.action = na.fail)

anova(gam1, gam2, gam3, gam4)







```
These results show that there may not be a significant need to use non-linear parametrics in this case. The most significant model is the one that is completely linear. The model using only a log of Expenditures is also very significant. 





