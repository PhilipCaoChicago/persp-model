---
title: "Problem Set 9 | MACS 301"
author: "Julian McClellan"
date: "Due 3/6/17"
output:
  html_document: default
  pdf_document: 
    latex_engine: lualatex
---
```{r setup, echo = FALSE, include = FALSE, message = FALSE}
library(tidyverse)
library(forcats)
library(broom)
library(modelr)
library(stringr)
library(ISLR)
library(titanic)
library(rcfss)
library(pROC)
library(grid)
library(gridExtra)
library(FNN)
library(kknn)
library(purrr)
library(tree)
library(gbm)
library(randomForest)
library(caret)

knitr::opts_chunk$set(cache = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      echo = FALSE
                      )
options(digits = 3)
theme_set(theme_minimal())
```

# Attitudes towards feminists

#### 1. Split the data into a training set (70%) and a validation set (30%). *Be sure to set your seed prior to this part of your code to guarantee reproducibility of results.*

We utilize 70% of the data as training data, and the remaining 30% as testing data.

```{r echo = TRUE}
fem_df <- read_csv('data/feminist.csv') 
  # mutate_each(funs(as.factor(.)), income, female, dem, rep)
  
set.seed(1234) # For reproducibility
fem_split <- resample_partition(fem_df, c(test = .3, train = .7))

fem_train <- fem_df[fem_split$train$idx, ]
fem_test <- fem_df[fem_split$test$idx, ]
```

***

#### 2. Calculate the test MSE for KNN models with K = 5, 10, 15, …, 100, using whatever combination of variables you see fit. Which model produces the lowest test MSE?

```{r}
calc_mse <- function(model, data, response = 'feminist'){
  if (any(class(model) %in% c('lm', 'tree','randomForest'))) {
    x <- modelr:::residuals(model, data)
    mse <- mean(x ^ 2, na.rm = TRUE)
  } else if (any(class(model) == 'knnReg')) {
                             # Need to access response vector directly.
    mse <- mean((model$pred - data$data[data$idx, ][[response]]) ^ 2)
    return(mse)
  } else if (any(class(model) == 'kknn')) {# Weighted KNN
    mse <- mean((model$fitted.values - data$data[data$idx, ][[response]]) ^ 2)
      # mean((model$fitted.values - data$data[data$idx, ][[response]]) ^ 2)
    return(mse)
  } else if(any(class(model) == 'gbm')) {
    mse <- mean((data$data[data$idx, ][[response]] - 
                     predict(model, newdata = data, n.trees = model$n.trees)) ^ 2)
    return(mse)
  }
}


data_frame(k_vals = seq(5, 100, by = 5),
           knn_models = map(k_vals, ~ 
                              knn.reg(as.data.frame(select(fem_train, -feminist)), 
                                      y = as.vector(as.data.frame(select(fem_train, feminist))), 
                                                    test = as.data.frame(select(fem_test, -feminist)),
                                                    k = .)
                            ),
           mse = map_dbl(knn_models, ~ mean((fem_test$feminist - .$pred) ^ 2))
) %>% 
{.} -> df

min_mse_k <- df$k_vals[which.min(df$mse)]
best_knn_model <- df$knn_models[[which.min(df$mse)]]

df %>%
  ggplot(aes(k_vals, mse)) +
    geom_line() +
    scale_x_continuous(breaks = append(c(25, 50, 75, 100), min_mse_k)) +
    geom_vline(aes(xintercept = min_mse_k), color = 'red', linetype = 'dashed') +
    annotate('text', x = 44, y = 500, label = sprintf('Minimum MSE at %d neighbors in KNN Regression', min_mse_k)) + 
     labs(title = 'Test MSE of KNN Regression on Feminist Warmth Score',
         subtitle = 'All Predictors Used | Values of k: 5, 10, 15, . . . 100',
         y = 'Test MSE',
         x = 'Number of Neighbors (k)',
         color = '')
```

***

#### 3. Calculate the test MSE for weighted KNN models with K = 5, 10, 15, …, 100 using the same combination of variables as before. Which model produces the lowest test MSE?

```{r}
data_frame(k_vals = seq(5, 100, by = 5),
           knn_models = map(k_vals, ~ 
                              kknn(feminist ~ ., train = fem_train, 
                                   test = fem_test, k = .)
                            ),
           mse = map_dbl(knn_models, ~ mean((fem_test$feminist - .$fitted.values) ^ 2))
) %>% 
{.} -> df

min_mse_k <- df$k_vals[which.min(df$mse)]
best_wknn_model <- df$knn_models[[which.min(df$mse)]]

df %>%
  ggplot(aes(k_vals, mse)) +
    geom_line() +
    labs(title = 'Test MSE of Weighted KNN Regression on Feminist Warmth Score',
         subtitle = 'All Predictors Used | Values of k: 5, 10, 15, . . . 100',
         y = 'Test MSE',
         x = 'Number of Neighbors (k)', 
         color = '') +
    scale_x_continuous(breaks = append(c(25, 50, 75, 100), min_mse_k)) +
    geom_vline(aes(xintercept = min_mse_k), color = 'red', linetype = 'dashed') +
    annotate('text', x = 60, y = 500, label = sprintf('Minimum MSE at %d neighbors in KNN Regression', min_mse_k)) +
    annotate('text', x = 61, y = 480, label = 'Test MSE appears to be monotonically decreasing with k')
```

***

#### 4. Compare the test MSE for the best KNN/wKNN model(s) to the test MSE for the equivalent linear regression, decision tree, boosting, and random forest methods using the same combination of variables as before. Which performs the best? Why do you think this method performed the best, given your knowledge of how it works?

```{r}
df <- data_frame(model = list('Best KNN (knn)' = best_knn_model, 'Best wKNN (kknn)' = best_wknn_model,
                              'Linear Regression (lm) ' = lm(feminist ~ ., data = fem_split$train),
                              'Decision Tree (tree)' = tree(feminist ~ ., data = fem_split$train),
                              'Boosting (2000 Trees)' = gbm(feminist ~ ., data = fem_split$train, distribution = 'gaussian',
                                                n.trees = 2000, interaction.depth = 2), 
                              'Random Forest (500 Trees)' = randomForest(feminist ~ ., data = fem_split$train,
                                                                         importance = TRUE, ntree = 500)),
                 mse = map_dbl(model, ~ calc_mse(., data = fem_split$test))
)

stats = list('min_mse' = min(df$mse), 'min_mse_model_name' = names(df$model[which.min(df$mse)]))
tdf <- data_frame(model = list('Best KNN' = best_knn_model, 'best wKNN' = best_wknn_model),
                  vals = c(5, 4))

df %>%
  ggplot(aes(names(model), mse)) +
    geom_col(aes(fill = names(model)), width = 1, show.legend = FALSE) +
    coord_flip() + 
    labs(title = 'Test MSE for Feminist Warmth Score for Various Methods (All Predictors)',
         subtitle = sprintf('Best Method: %s (%.3f Test MSE)', stats$min_mse_model_name, stats$min_mse),
         x = '',
         y = 'Test MSE',
      fill = 'Method') +
    theme(plot.title = element_text(hjust = 2))
```

I think that the boosting method, with 2000 trees worked, because the process of boosting iteratively works to reduce the size of residuals with each tree created. Additionally, I tried to choose a number of trees that was high enough to significantly reduce the residuals on the training set, but low enough to prevent overfitting.

***

# Voter turnout and depression 

##### 1. Split the data into a training and test set (70/30).

```{r, echo = TRUE}
mhealth_df <- na.omit(read_csv('data/mental_health.csv'))
  # mutate_each(funs(as.factor(.)), income, female, dem, rep)
  
set.seed(1234) # For reproducibility
mhealth_split <- resample_partition(mhealth_df, c(test = .3, train = .7))

mhealth_train <- mhealth_df[mhealth_split$train$idx, ]
mhealth_test <- mhealth_df[mhealth_split$test$idx, ]
```

***

#### 2. Calculate the test error rate for KNN models with K = 1, 2, …, 10, using whatever combination of variables you see fit. Which model produces the lowest test MSE?

```{r}
data_frame(k_vals = seq(5, 100, by = 5),
           knn_classifiers = map(k_vals, ~ 
                              class::knn(as.data.frame(select(mhealth_train, -vote96)), 
                                      cl = as.data.frame(select(mhealth_train, vote96))$vote96, 
                                                    test = as.data.frame(select(mhealth_test, -vote96)),
                                                    k = .)
                            ),
           test_err = map_dbl(knn_classifiers, ~ mean(unlist(.) != mhealth_test$vote96, na.rm = TRUE))
) %>% 
{.} -> df

min_test_err_k <- df$k_vals[which.min(df$test_err)]
best_knn_classifier <- df$knn_classifiers[[which.min(df$test_err)]]

df %>%
  ggplot(aes(k_vals, test_err)) +
    geom_line() +
    geom_vline(aes(xintercept = min_test_err_k), color = 'red', linetype = 'dashed') +
    annotate('text', x = 45, y = .31, label = sprintf('Minimum Test Error Rate at %d neighbors in KNN Classification', min_test_err_k)) + 
    scale_x_continuous(breaks = append(c(25, 50, 75, 100), min_test_err_k)) +
    labs(title = 'Test Error of KNN Classification on Voting in 1996',
         subtitle = 'All Predictors Used | Values of k: 5, 10, 15, . . . 100',
         y = 'Test Error Rate',
         x = 'Number of Neighbors (k)') 
```

*** 

#### 3. Calculate the test error rate for weighted KNN models with K = 1, 2, …, 10 using the same combination of variables as before. Which model produces the lowest test error rate?

```{r}
data_frame(k_vals = seq(5, 100, by = 5),
           knn_classifiers = map(k_vals, 
                                 ~ kknn(vote96 ~ ., train = mutate(mhealth_train, vote96 = factor(vote96)),
                                   test = mutate(mhealth_test, vote96 = factor(vote96)),
                                   k = .)
                            ),
           test_err = map_dbl(knn_classifiers, ~ mean(mhealth_test$vote96 != .$fitted.values))
) %>% 
{.} -> df

min_test_err_k <- df$k_vals[which.min(df$test_err)]
best_wknn_classifier <- df$knn_classifiers[[which.min(df$test_err)]]

df %>%
  ggplot(aes(k_vals, test_err)) +
    geom_line() +
    geom_vline(aes(xintercept = min_test_err_k), color = 'red', linetype = 'dashed', show.legend = TRUE) +
    annotate('text', x = 45, y = .296, label = sprintf('Minimum Test Error Rate at %d neighbors in KNN Classification', min_test_err_k)) +     scale_x_continuous(breaks = append(c(25, 50, 75, 100), min_test_err_k)) +
    labs(title = 'Test Error of KNN Classification on Voting in 1996',
         subtitle = 'All Predictors Used | Values of k: 5, 10, 15, . . . 100',
         y = 'Test Error Rate',
         x = 'Number of Neighbors (k)',
         color = '')
```

***

#### 4. Compare the test error rate for the best KNN/wKNN model(s) to the test error rate for the equivalent logistic regression, decision tree, boosting, random forest, and SVM methods using the same combination of variables as before. Which performs the best? Why do you think this method performed the best, given your knowledge of how it works?

```{r}
calc_test_err <- function(model, data, response = 'vote96'){
  actual <- data$data[data$idx, ][[response]]
  
  if (class(model) == 'factor') { # For output of class::knn
    test_err <- mean(model != data$data[data$idx, ][[response]], na.rm = TRUE)
    
  } else if (class(model) == 'tree') {
    pred <- predict(model, data, type = 'class')
    test_err <- mean(pred != actual, na.rm = TRUE)
    
  } else if (any(class(model) == 'kknn')) {# Weighted KNN
    test_err <- 
      mean((as.numeric(levels(model$fitted.values))[model$fitted.values] - data$data[data$idx, ][[response]]) ^ 2)
      # mean((model$fitted.values - data$data[data$idx, ][[response]]) ^ 2)

  } else if (any(class(model) == 'gbm')) {
    # From tree methods notes
    test_err <- predict(model, newdata = as_tibble(data), type = 'response', n.trees = model$n.trees) %>%
      (function(x) round(x) != data$data[data$idx, ][[response]]) %>%
      mean()
    
  } else if (any(class(model) == 'randomForest')){
    pred_factor <- predict(model, data, type = 'class')
    pred <- as.numeric(levels(pred_factor))[pred_factor]

    test_err <- mean(pred != actual, na.rm = TRUE)
  } else if (all(class(model) == c('glm', 'lm'))){
    probs <- predict(model, data, type = 'response')
    pred <- ifelse(probs > .5, 1, 0)
    test_err <- mean(pred != actual, na.rm = TRUE)
  }
  if (exists('test_err')){
    return(test_err)
  } else {
    print(class(model))
  }
  
  
}

df <- data_frame(model = list('Best KNN (class::knn)' = best_knn_classifier, 'Best wKNN (kknn)' = best_wknn_classifier,
                              'Logistic Regression (glm) (.5 threshold) ' = glm(vote96 ~ ., data = mhealth_split$train, family = binomial),
                              'Decision Tree (tree)' = tree(factor(vote96) ~ ., data = mhealth_split$train),
                              'Boosting (2000 Trees)' = gbm(vote96 ~ ., data = mhealth_split$train, 
                                                            distribution = 'gaussian',
                                                n.trees = 2000, interaction.depth = 2), 
                              'Random Forest (500 Trees)' = randomForest(factor(vote96) ~ ., data = mhealth_split$train,
                                                                         importance = TRUE, ntree = 500))
                 ,
                 test_err = map_dbl(model, ~ calc_test_err(., data = mhealth_split$test))
)

stats = list('min_test_err' = min(df$test_err), 'min_test_err_model_name' = names(df$model[which.min(df$test_err)]))

df %>%
  ggplot(aes(names(model), test_err)) +
    geom_col(aes(fill = names(model)), width = 1, show.legend = FALSE) +
    coord_flip() + 
    labs(title = 'Test Error for Voting in 1996 for Various Classifiers (All Predictors)',
         subtitle = sprintf('Best Method: %s (%.3f Test Error)', stats$min_test_err_model_name, stats$min_test_err),
         x = '',
         y = 'Test Error',
      fill = 'Method') +
    theme(plot.title = element_text(hjust = 2))
```

