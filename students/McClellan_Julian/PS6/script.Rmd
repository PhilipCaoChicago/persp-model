---
title: "Problem Set 6 | MACS 301"
author: "Julian McClellan"
date: "Due 2/20/17"
output:
  pdf_document: 
    latex_engine: lualatex
  html_document: default
---
```{r setup, echo = FALSE, include = FALSE}
library(ggplot2)
library(tidyverse)
library(broom)
library(modelr)
library(pROC)
library(MASS)
library(stargazer)
knitr::opts_chunk$set(cache = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      echo = FALSE)
df.gss = read.csv('data/gss2006.csv')
df.mhealth = read.csv('data/mental_health.csv')
```

# Part 1: Modelling Voter Turnout

## Describe the Data

```{r describe_p1}
ggplot(df.mhealth, aes(vote96, fill = ifelse(vote96 == 1, 'Voted', 'Did not Vote'))) +
  geom_bar() + 
  labs(title = 'Voter Turnout in 1996', x = 'Vote Status', y = 'Number of people') +
  scale_x_continuous(breaks = NULL) +
  guides(fill = guide_legend(title = ''))

ggplot(df.mhealth, aes(mhealth_sum, vote96)) +
  geom_point() +
  geom_smooth(method = lm) + 
  scale_y_continuous(breaks = c(0, 1)) + 
  labs(title = "Voting in 1996 versus Mental Health Index",
       y = "Voted (1) | Did not Vote (0)",
       x = "Mental Health Index (higher = worse mental health)")
```

The unconditional probability of a given individual turning out to vote is: `r round(100 * sum(df.mhealth$vote96, na.rm = TRUE) / length(df.mhealth$vote96), 2)`%.  

The scatterplot with the linear smoothing line tells us that in general, higher values of the mental health index, `mhealth_sum` (worse mental health) are associated with not voting in 1996. However, the problem with this graph is that a smooth fit line assumes the response variable can cover all real numbers. In our case, the response variable is either 1 (voted) or 0, not voted. Thus, interpretation of the line does make sense in the context of 'voting' or 'not voting'.

## Basic model

```{r basic_model, results = 'asis'}
logit.mh_vt <- glm(vote96 ~ mhealth_sum, data = df.mhealth, family = binomial)
stargazer(logit.mh_vt, type = 'latex', title = 'Summary of Voting Status Regressed on Mental Health', header = FALSE)

param <- logit.mh_vt$coefficients[2]

logit2prob <- function(x){
  exp(x) / (1 + exp(x))
}

prob2odds <- function(x){
  x / (1 - x)
}

prob2logodds <- function(x){
  log(prob2odds(x))
}

df.mhealth %>%
  dplyr::select(vote96, mhealth_sum) %>%
  add_predictions(logit.mh_vt, var = 'logit') %>%
  mutate(prob = logit2prob(logit)) %>%
  mutate(odds = prob2odds(prob)) %>%
  na.omit() %>%
  {.} -> pred.mh_vt
```
### 1. 
The relationship between mental health (`mhealth_sum`) and voter turnout is stastistically significant, with a p-value approaching 0 (`r coef(summary(logit.mh_vt))[2,4]`). Additionally, we see that the change in the log-odds associated with a one unit increase in `mhealth_sum` (worse mental health) is `r param`. In other words, the odds ratio associated with a one unit increase in `mhealth_sum` is `r exp(param)`. This appears to be substantively significant as well in the negative direction. However, we will confirm this with the following graphs.

### 2.

```{r log_odds_graph}
ggplot(aes(mhealth_sum), data = pred.mh_vt) + 
  geom_line(aes(y = logit)) + 
  labs(title = "Log Odds of Voting in '96 vs. Mental Health Status", 
       x = "Mental Health Status (higher = worse mental health)",
       y = "Log odds of Voting")
```

Looks linear, that's good. The estimated parameter, is given by default in terms of log odds, and was previously stated as: `r param`.  

### 3.
```{r odds_graph}
ggplot(aes(mhealth_sum), data = pred.mh_vt) + 
  geom_line(aes(y = odds)) + 
  labs(title = "Odds of Voting in '96 vs. Mental Health Status", 
       x = "Mental Health Status (higher = worse mental health)",
       y = "Odds of Voting")
```

### 4.
```{r probs_graph}
ggplot(aes(mhealth_sum), data = pred.mh_vt) + 
  geom_line(aes(y = prob)) + 
  labs(title = "Probability of Voting in '96 vs. Mental Health Status", 
       x = "Mental Health Status (higher = worse mental health)",
       y = "Probability of Voting")

tibble(mhealth_sum = 0:16) %>%
  add_predictions(logit.mh_vt, var = 'logit') %>%
  mutate(prob = logit2prob(logit)) %>%
  {.} -> diff_grid

dif.21 = diff_grid[3,]$prob - diff_grid[2,]$prob
dif.65 = diff_grid[7,]$prob - diff_grid[6,]$prob
```

The first difference for an increase in the mental health index from 1 to 2 is: `r dif.21`.  
The first difference for an increase in the mental health index from 5 to 6 is: `r dif.65`.

### 5.
```{r model_stats}
pred.mh_vt %>%
  na.omit() %>%
  mutate(pred_vote = ifelse(prob > .5, 1, 0)) %>%
  {.} -> pred.mh_vt
  
acc_rate <- mean(pred.mh_vt$vote96 == pred.mh_vt$pred_vote)
e2 <- 1 - acc_rate
e1 <- 1 - mean(pred.mh_vt$vote96 == 1)

pre <- (e1 - e2) / e1

auc_score = auc(pred.mh_vt$vote96, pred.mh_vt$pred_vote)
```

Given a threshhold of .5, the accuracy rate is: `r round(100 * acc_rate, 2)`% and the proportional reduction in error is: `r round(100 * pre, 2)`%. The AUC is `r auc_score`, and the AUC score takes into account all possible threshhold values. 

I don't think this is a very good model. The proportional reduction in error is a good indicator of this. A proportional reduction in error of `1.62%` is a pretty negligible increase over the useless classifier. Additionally, we see that the AUC score only provides a `r auc_score - .5` increase in AUC score over the useless classifier.

## Multiple Variable Model

### 1.
  * The random component of the probability distribution, `vote96` is distributed as a binomial random          variable. Each individual $vote96_i$ (each row of our dataframe) is a Bernoulli Trial and thus the sum      of all individual $vote96_{i}\ 's$ (i.e. the entire column `vote96`) is distributed as a binomial random     variable. $$Pr(\sum_{i=1}^{n}vote96_i = k|p) = \binom{n}{k}p^k(1-p)^{n-k}$$
  
  * In our case, the linear predictor is: $$vote96_{i} = \beta_{0} + \beta_{1}mhealth\_sum + \beta_{2}age + \beta_{3}educ + \beta_{4}black + \beta_{5}female + \beta_{6}married + \beta_{7}inc10$$ 
    * Note that this is the linear predictor for a model utilizing *all* possible explanatory variables. The       model I utilize may or may not use all of the explanatory variables. 
  
  * Our link function is: $$g(vote96_i) = \frac{e^{vote96_i}}{1 + e^{vote96_i}}$$

### 2.
```{r est_model, echo = TRUE, results = 'asis', hold = TRUE, tidy.opts=list(width.cutoff=60)}
# Define a full and a null model. 
logit.mh_all <- glm(vote96 ~ ., data = df.mhealth,
                    family = binomial)
logit.mh_none <- glm(vote96 ~ 1, data = df.mhealth, family = binomial)

# We will use backward stepwise AIC selection to select a model
# In simple terms, AIC offers a tradeoff between model parsimony and log likelihood.
logit.mh_bselect <- stepAIC(logit.mh_all, trace = 0)
stargazer(logit.mh_bselect, type = 'latex', title = 'Results of Backwards AIC selected Model (Logit)', header = FALSE)
```

### 3.
```{r interp_results}
acc_pre_auc = function(df, logit_model, dep_var = 'vote96', thold = .5){
  df %>%
    na.omit() %>%
    add_predictions(logit_model, var = 'logit') %>%
    mutate(prob = logit2prob(logit)) %>%
    mutate(odds = prob2odds(prob)) %>%
    mutate(pred = ifelse(prob > thold, 1, 0)) %>%
    {.} -> pred
  
  acc_rate <- mean(pred[[dep_var]] == pred$pred)
  e2 <- 1 - acc_rate
  e1 <- 1 - mean(pred[[dep_var]] == 1)
  pre <- (e1 - e2) / e1
  auc_score = auc(pred[[dep_var]], pred$prob)
  return(list('acc_rate' = acc_rate, 'pre' = pre, 'auc' = auc_score))
}

bsel_crit <- acc_pre_auc(df.mhealth, logit.mh_bselect)
```
From the above table, we see the backwards AIC selection has resulted in a model with 5 predictor variables, not including the intercept. The binary predictors `black` and `female` were left out. AIC selection involves the calculation of maximum likelihood, and thus other predictors likely provided greater maximum likelihood than `black` and `female`. All of these predictors are significant at the `.05` level, except `married`, which is only significant at the `.1` level. With a .5 threshold, the accuracy rate of this model is `r round(100 * bsel_crit$acc_rate, 2)`%, the proportional reduction in error over the useless classifier is `r round(100 * bsel_crit$pre, 2)`%, and the AUC (over all threshold values) is `r bsel_crit$auc`.

All of the predictors, with the exception of `mhealth_sum`, have positive coefficients. These coefficients represent the effect a one unit increase of the predictor, with all other predictors held constant, has on the log-odds of vote participation. However, it is beneficial to visualize the effect of our predictors on actual predicted probabilities.

Let's focus on one of the more statistically and substantively significant predictors, `educ` (years of education) and look at its affect on predicted probability. Note, that we cannot simply graph predicted probability against `educ`, as there are other predictors to take into account. Thus, for the non-binary variables of `age`, `mhealth_sum`, and `inc10` we simply hold those values constant at their median values within the dataset. We will graph two predicted probability curves, one for married people, and the other for unmarried people.
```{r graph_pred_prob}
df.mhealth %>%
  data_grid(educ, married, .model = logit.mh_bselect) %>%
  add_predictions(logit.mh_bselect, var = 'logit') %>%
  mutate(prob = logit2prob(logit)) %>%
  {.} -> grid.bsel.educ 

ggplot(grid.bsel.educ, aes(x = educ, y = prob, color = ifelse(married == 1, 'Married', 'Unmarried'))) +
  geom_line() +
  labs(title = 'Effect of Education on Voting (married and unmarried)',
       subtitle = 'Note that income, age, and mental health are fixed at their median values.',
    x = 'Years of Education', y = 'Predicted Probability of Voting in 1996') +
  guides(color = guide_legend('')) + 
  scale_y_continuous(breaks = c(0, .25, .5, .75, 1))
```

Thus, we see the effect of `educ` the most impactful non-binary predictor on predicted voting probability, and `married` also results in a shift upward in predicted probability.

# Part 2: Modeling TV Consumption

## Estimate a Regression Model

### 1.
  * The random component of the probability distribution, `tvhours` is distributed as a poisson random        variable. $$Pr(tvhours = k|\lambda) = \frac{\lambda^{k}e^{-\lambda}}{k!}$$
  
  * The linear predictor of a model utilizing all of the possible explanatory variables in the GSS survey is: $$tvhours_{i} = \beta_{0} + \beta_{1}age + \beta_{2}childs +     \beta_{3}educ + \beta_{4}female + \beta_{5}grass + \beta_{6}hrsrelax + \beta_{7}black$$ $$+ \beta_{8}social_connect + \beta_{9}voted04 + \beta_{10}xmovie + \beta_{11}zodiac + \beta_{12}dem + \beta_{13}rep + \beta_{14}ind$$
  * Our link function is: $$g(vote96_i) = \log(tvhours_{i})$$
  
### 2.
```{r est_pois_model, echo = TRUE, results = 'asis', tidy.opts=list(width.cutoff=60)}
# Define a full and a null model. 
df.gss <- na.omit(df.gss)

pois.gss_all <- glm(tvhours ~ ., data = df.gss,
                    family = poisson)
pois.gss_none <- glm(tvhours ~ 1, data = df.gss, family = poisson)

# We will use backward stepwise AIC selection to select a model
# In simple terms, AIC offers a tradeoff between model parsimony and log likelihood.
pois.gss_bselect <- stepAIC(pois.gss_all, trace = 0)
stargazer(pois.gss_bselect, type = 'latex', title = 'Results of Backwards AIC selected Model (GLM | Poisson)', header = FALSE)
```


### 3.
```{r interp_results_fightme}
bsel_crit <- acc_pre_auc(df.gss, pois.gss_bselect, 'tvhours')
```
Looking at the table below, we see the backwards AIC selection has resulted in a model with 4 predictor variables, not including the intercept. Thankfully, backwards AIC selection left out variables that wouldn't make much sense to affect TV hours watched, including the Zodiac symbols and whether or not someone saw an X-rated movie or voted in 2004. All of the predictors are significant at the `.05` level, except `grass`, which is only significant at the `.1` level.  With a .5 threshold, the accuracy rate of this model is `r round(100 * bsel_crit$acc_rate, 2)`%, the proportional reduction in error over the useless classifier is `r round(100 * bsel_crit$pre, 2)`%, and the AUC (over all threshold values) is `r bsel_crit$auc`.

Two of the predictors, `educ` (years of education), and `grass` (believes marijuana should be legalized), have negative coefficients, and the other two, `hrsrelax` and `black` have positive coefficients. These coefficients represent the effect a one unit increase of the predictor, with all other predictors held constant, has on the log count of `tvhours`. However, as before it is beneficial to visualize the effect of our predictors on actual predicted probabilities.

Let's focus on one of the more substantively significant non-binary predictors: `hrsrelax` (the hours in a day one has to relax), and look at its affect on predicted count. Note, that we cannot simply graph predicted count against `hrsrelax`, as there are other predicted variables to take into account. Thus, for the non-binary variable `educ` we simply hold this value constant at the median values within the dataset. We will plot 4 different lines for the interactions of the two-binary variables `grass` and `black`.

```{r graph_pred_prob_pois}
df.gss %>%
  data_grid(hrsrelax, black, grass, .model = pois.gss_bselect) %>%
  add_predictions(pois.gss_bselect, var = 'log_count') %>%
  mutate(count = exp(log_count), race_weed = paste(ifelse(grass, 'Legalize Weed', "Don't Legalize Weed"), 
                                                   '+', 
                                                   ifelse(black, "Black", "Non_Black"))) %>%
  {.} -> grid.bsel.hrsrelax

ggplot(grid.bsel.hrsrelax, aes(x = hrsrelax, y = count, 
                               color = race_weed)) +
  geom_line() +
  labs(title = 'Effect of Hours of Lesiure on Predicted Hours of TV Watched per day',
       subtitle = 'Note that years of education is fixed at its median value.',
    x = 'Hours of Leisure per day', y = 'Predicted Hours of TV watched per day') +
  guides(color = guide_legend('')) + 
  scale_y_continuous(breaks = c(0, .25, .5, .75, 1))
```
  
  As one could have seen from the table, but what is now evident from this table, is that if one is Black, and with all other predictors held constant, that there is a larger jump in predicted hours of TV watched per day than there is if one believes in legalizing marijuana. To be honest this seems to go against the stoner stereotype.