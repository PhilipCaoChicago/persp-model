{
    "collab_server" : "",
    "contents" : "# import packages\nlibrary(tidyverse)\nlibrary(data.table)\nlibrary(modelr)\nlibrary(broom)\nlibrary(tree)\nlibrary(randomForest)\nlibrary(ggdendro) #devtools::install_github(\"bensoltoff/ggdendro\")\nlibrary(forcats)\nlibrary(gbm)\nlibrary(pROC)\nlibrary(e1071)\n\n\n# import data\nbiden <- fread('data/biden.csv')\nmhealth <- fread('data/mental_health.csv')\nsimpson <- fread('data/simpson.csv')\n\n# set seed for reproducibility\nset.seed(0)\n\n# define a function to get mse\nmse <- function(model, data) {\n  x <- modelr:::residuals(model, data)\n  mean(x ^ 2, na.rm = TRUE)\n}\n\nerr.rate.tree <- function(model, data) {\n  data <- as_tibble(data)\n  response <- as.character(model$terms[[2]])\n  \n  pred <- predict(model, newdata = data, type = \"class\")\n  actual <- data[[response]]\n  \n  return(mean(pred != actual, na.rm = TRUE))\n}\n\n#-----------------------------------------------------#\n# Part 3: OJ Simpson [4 points]\n#-----------------------------------------------------#\n# Part 3: Explain the impact of an individual's race on their beliefs about OJ Simpson's guilt\nsimpson_logit1 <- glm(guilt ~ black + hispanic, data = (simpson %>% na.omit()), family='binomial') # only race predictors\nsimpson_logit2 <- glm(guilt ~ ., data = (simpson %>% na.omit()), family='binomial') # all predictors\n\nsummary(simpson_logit1)\nsummary(simpson_logit2)\n\nsimpson$guilt\n#-----------------------------------------------------#\n# Part 3: Predict the impact of an individual's race on their beliefs about OJ Simpson's guilt\n# Prepare data\nsimpson_pred <- simpson %>%\n  na.omit() %>% # remove missing values\n  model.matrix(~ ., data=.) %>% # binarize categorical predictors\n  as.data.table() %>%\n  select(-`(Intercept)`)\n# simplify colnames\ncolnames(simpson_pred)  <- c('guilt', 'dem', 'rep', 'ind', 'age', 'educ_hs', 'educ_not_hs', 'educ_ref', 'educ_some_col',\n                        'female', 'black', 'hispanic', 'inc_30to50', 'inc_50to75', 'inc_over75', 'inc_ref', 'inc_under15')\n\n# split data into train and test sets  \nsimpson_split <- resample_partition(simpson_pred, c(test = 0.3, train = 0.7))\nsimpson_train <- simpson_pred[simpson_split$train$idx]\nsimpson_test <- simpson_pred[simpson_split$test$idx]\n\n# fit models to compare\nsimpson_logit <- glm(guilt ~ ., data = simpson_train, family='binomial') # logistic regression\nsimpson_rf <- randomForest(as.factor(guilt) ~ ., data = simpson_train, ntree = 5000)\nsimpson_bst <- gbm(guilt ~ ., data = simpson_train, n.trees = 5000)\nsimpson_svm_lin <- svm(guilt ~ ., data = simpson_train, kernel = \"linear\", scale = FALSE, probability=TRUE)\nsimpson_svm_poly <- svm(guilt ~ ., data = simpson_train, kernel = \"polynomial\", scale = FALSE, probability=TRUE)\nsimpson_svm_rad <- svm(guilt ~ ., data = simpson_train, kernel = \"radial\", scale = FALSE, probability=TRUE)\n\nsim_lin_tune <- tune(svm, guilt ~ ., data = as_tibble(simpson_train), kernel = \"linear\",\n                    range = list(cost = c(.01, .1, 1, 10, 100)))\nsim_poly_tune <- tune(svm, guilt ~ ., data = as_tibble(simpson_train), kernel = \"polynomial\",\n                     range = list(cost = c(.01, .1, 1, 10, 100)))\nsim_rad_tune <- tune(svm, guilt ~ ., data = as_tibble(simpson_train), kernel = \"radial\",\n                    range = list(cost = c(.01, .1, 1, 10, 100)))\nsimpson_svm_ltuned <- sim_lin_tune$best.model\nsimpson_svm_ptuned <- sim_poly_tune$best.model\nsimpson_svm_rtuned <- sim_rad_tune$best.model\n\n\n# predict\nfitted_logit <- predict(simpson_logit, as_tibble(simpson_test), type = \"response\")\nfitted_rf <- predict(simpson_rf, as_tibble(simpson_test), type = \"prob\")[,2]\nfitted_bst <- predict(simpson_bst, as_tibble(simpson_test), type = \"response\", n.trees=5000)\nfitted_svm_lin <- predict(simpson_svm_lin, as_tibble(simpson_test), decision.values = TRUE, probability = TRUE) %>% attributes\nfitted_svm_poly <- predict(simpson_svm_poly, as_tibble(simpson_test), decision.values = TRUE, probability = TRUE) %>% attributes\nfitted_svm_rad <- predict(simpson_svm_rad, as_tibble(simpson_test), decision.values = TRUE, probability = TRUE) %>% attributes\n\n#-----------------------------------------------------#\n# Part 3: Predict -- the effectiveness of model (test error rate)\nmean(round(fitted_logit) != simpson_test$guilt)\nmean(round(fitted_rf) != simpson_test$guilt)\nmean(round(fitted_bst) != simpson_test$guilt)\nmean(round(fitted_svm_lin$decision.values) != simpson_test$guilt)\nmean(round(fitted_svm_poly$decision.values) != simpson_test$guilt)\nmean(round(fitted_svm_rad$decision.values) != simpson_test$guilt)\n\nattr(fitted_svm_rad,'probabilities')\n?predict.svm()\n\n#-----------------------------------------------------#\n# Part 3: Predict -- the effectiveness of model (PRE)\n\n#-----------------------------------------------------#\n# Part 3: Predict -- the effectiveness of model (ROC curves/AUC)\nroc_logit <- roc(as_tibble(simpson_test)$guilt, fitted_logit)\nroc_rf <- roc(as_tibble(simpson_test)$guilt, fitted_rf)\nroc_bst <- roc(as_tibble(simpson_test)$guilt, fitted_bst)\nroc_svm_lin <- roc(as_tibble(simpson_test)$guilt, as.numeric(fitted_svm_lin$decision.values))\nroc_svm_poly <- roc(as_tibble(simpson_test)$guilt, as.numeric(fitted_svm_poly$decision.values))\nroc_svm_rad <- roc(as_tibble(simpson_test)$guilt, as.numeric(fitted_svm_rad$decision.values))\n\nplot(roc_logit, print.auc = TRUE, col = \"red\", print.auc.x = .2)\nplot(roc_rf, print.auc = TRUE, col = \"blue\", print.auc.x = .2, print.auc.y = .425, add = TRUE)\nplot(roc_bst, print.auc = TRUE, col = \"orange\", print.auc.x = .2, print.auc.y = .35, add = TRUE)\nplot(roc_svm_lin, print.auc = TRUE, col = \"green\", print.auc.x = .2, print.auc.y = .275, add = TRUE)\nplot(roc_svm_poly, print.auc = TRUE, col = \"purple\", print.auc.x = .2, print.auc.y = .2, add = TRUE)\nplot(roc_svm_rad, print.auc = TRUE, col = \"cyan\", print.auc.x = .2, print.auc.y = .125, add = TRUE)\n",
    "created" : 1488805047102.000,
    "dirty" : true,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2017328196",
    "id" : "50C06914",
    "lastKnownWriteTime" : 1488805079,
    "last_content_update" : 1488814682013,
    "path" : "~/UChicago/Coursework2_winter/MACS 30100/PS8/Kang_persp-model_PS8_part3.R",
    "project_path" : "Kang_persp-model_PS8_part3.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}